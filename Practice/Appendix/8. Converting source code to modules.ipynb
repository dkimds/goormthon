{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b72ff04a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<br>\n",
    "\n",
    "#### - **prepare_data**.py : 데이터 다운로드 & 데이터 로더 생성을 위한 코드\n",
    "<br>\n",
    "\n",
    "#### - **train_funcs**.py : 모델 학습과 관련된 함수들을 위한 코드\n",
    "<br>\n",
    "\n",
    "#### - **build_model**.py : 모델 생성을 위한 코드\n",
    "<br>\n",
    "\n",
    "#### - **train**.py : 모델 학습을 위한 코드\n",
    "<br>\n",
    "\n",
    "#### - **utils**.py : Utility 함수들을 위한 코드\n",
    "<br>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85eac79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/goormthon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 자동완성을 위한 import \n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchmetrics import Accuracy # PyTorch metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9cf078",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 1.  prepare_data.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> 데이터 다운로드 & 데이터 로더 생성을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b3a2693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_module/prepare_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/prepare_data.py \n",
    "# \"Write a file\" with the following source-codes\n",
    "\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader # class for loading the dataset (Dataset -> Batches)\n",
    "\n",
    "\n",
    "def create_dataloaders(train_dir, \n",
    "                       test_dir, \n",
    "                       train_transform, \n",
    "                       test_transform,\n",
    "                       batch_size):\n",
    "\n",
    "    with zipfile.ZipFile(\"data_food101/Food101.zip\", \"r\") as zip_f:\n",
    "        print(\"Unzipping the dataset.\") \n",
    "        zip_f.extractall(\"data_food101/data\") # \"extract\" \"all\" files \n",
    "\n",
    "        \n",
    "    # 1) image directories -> image transformation -> ImageFolder\n",
    "    \n",
    "    train_imgfolder = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
    "    test_imgfolder  = datasets.ImageFolder(root=test_dir,  transform=train_transform)\n",
    "\n",
    "    class_names = train_imgfolder.classes\n",
    "\n",
    "    \n",
    "    # 2) ImageFolder -> DataLoader (iterable for mini-batches)\n",
    "    \n",
    "    torch.manual_seed(42) # \"Manually\" set the \"seed\" \n",
    "    \n",
    "    train_dataloader = DataLoader(train_imgfolder,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=True # GPU로의 데이터 로딩 속도 향상 @ https://bit.ly/3B70xIV\n",
    "    )\n",
    "    test_dataloader = DataLoader(test_imgfolder,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 pin_memory=True # GPU로의 데이터 로딩 속도 향상 @ https://bit.ly/3B70xIV\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e42a26",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 2.  build_model.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> 모델 생성을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43db5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_module/build_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/build_model.py\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn # 'N'eural 'N'etworks \n",
    "\n",
    "\n",
    "class CNNAugment_TinyVGG(nn.Module):\n",
    "\n",
    "    \n",
    "    def __init__(self, num_channels, num_filters, num_classes): \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block_entrance = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_channels, # will be '3' == R/G/B\n",
    "                      out_channels=num_filters, # num_filters == num of feature-maps == num of output channels\n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1,                 # default\n",
    "                      padding=1),               # 0 == 'valid', 1 == 'same'\n",
    "            nn.BatchNorm2d(num_filters),        # Batch-normalization on 2-Dimensional data\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(in_channels=num_filters,  # should be same as the number of \"channels of previous output\"\n",
    "                      out_channels=num_filters,\n",
    "                      kernel_size=(3, 3),\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(num_filters),        # Batch-normalization \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Default == kernel_size (자동으로 지정됨)\n",
    "        )\n",
    "        # [ 32, 3, 64, 64 ] -> [ 32, 10, 32, 32 ]\n",
    "        \n",
    "        \n",
    "        self.conv_block_hidden_1 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(num_filters), # Batch-normalization \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(num_filters), # Batch-normalization \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # [ 32, 10, 32, 32 ] -> [ 32, 10, 16, 16 ]\n",
    "        \n",
    "        \n",
    "        self.conv_block_hidden_2 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(num_filters), # Batch-normalization \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(num_filters, num_filters, (3, 3), padding=1),\n",
    "            nn.BatchNorm2d(num_filters), # Batch-normalization \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        # [ 32, 10, 16, 16 ] -> [ 32, 10, 8, 8 ]\n",
    "        \n",
    "        \n",
    "        self.classifier_block = nn.Sequential(\n",
    "            nn.Flatten(), # Flatten the input data\n",
    "            nn.Dropout(0.5), # Drop-out\n",
    "            nn.Linear(in_features=num_filters * 8 * 8, \n",
    "                      out_features=num_filters * 16 * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # Drop-out\n",
    "            nn.Linear(in_features=num_filters * 16 * 16, \n",
    "                      out_features=num_classes)\n",
    "        )\n",
    "        # [ 32, 10, 8, 8 ] -> [ 32, 10 * 8 * 8 ] -> [ 32, 10 * 16 * 16 ] -> [ 32, 10 ]\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv_block_enterance(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.conv_block_hidden_1(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.conv_block_hidden_2(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        x = self.classifier_block(x)\n",
    "        # print(x.shape)\n",
    "        \n",
    "        # 아래와 같이 코드를 작성하게되면 메모리가 크게 소요되는 변수 재할당 과정이 생략되므로 계산 속도가 향상됩니다. (https://bit.ly/3V16ZJy)\n",
    "        # return self.classifier_block(conv_block_hidden_2(conv_block_hidden_1(conv_block_entrance(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555cefe",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 3. train_funcs.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> 모델 학습과 관련된 함수들을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9044d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_module/train_funcs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/train_funcs.py\n",
    "\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm # we will use tqdm\n",
    "\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, metric, device):\n",
    "    \n",
    "    # 모델을 training mode로 설정 (default state)\n",
    "    model.train()\n",
    "    \n",
    "    # train-loss & train-accuracy for one epoch\n",
    "    train_loss = 0\n",
    "    train_acc  = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(dataloader): # X & y == a single batch\n",
    "        \n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # 1. (x 데이터를 모델에 넣고) 순방향 계산 진행 (forward pass)\n",
    "        logits = model(X)\n",
    "\n",
    "        # 2. (Batch) Training cost 계산 (Cost function 계산)\n",
    "        loss = loss_fn(logits, y) # cost of batch <- nn.CrossEntropyLoss() : built-in Softmax\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 3. Optimizer 내부의 이전 gradient 값 초기화 (Make \"grad\" to \"zero\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Back-propagation (\"Backward\" propagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Gradient descent 진행 (Take a \"step\" to update parameters)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. (Batch) Training accuracy 계산 \n",
    "        predicted_classes = logits.softmax(dim=1).argmax(dim=1)\n",
    "        train_acc += metric(predicted_classes, y).item() # calculate the batch accuracy & add to the epoch accuracy\n",
    "\n",
    "    # Batch 순회 종료 후\n",
    "    train_loss = train_loss / len(dataloader) # cost of batches / num of batches (calculate average)\n",
    "    train_acc  = train_acc  / len(dataloader) # acc  of batches / num of batches (calculate average)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, metric, device):\n",
    "    \n",
    "    # 모델을 evaluation mode로 설정\n",
    "    model.eval() \n",
    "    \n",
    "    # test-loss & test-accuracy for one epoch\n",
    "    test_loss = 0\n",
    "    test_acc  = 0\n",
    "    \n",
    "    with torch.inference_mode(): # Set \"inference mode\"\n",
    "        \n",
    "        for batch_idx, (X, y) in enumerate(dataloader): # X & y == a single batch\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "    \n",
    "            # 1. (x 데이터를 모델에 넣고) 순방향 계산 진행 (forward pass)\n",
    "            logits = model(X)\n",
    "\n",
    "            # 2. (Batch) Test cost 계산 (Cost function 계산)\n",
    "            loss = loss_fn(logits, y) # cost of batch <- nn.CrossEntropyLoss() : built-in Softmax\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # 3. (Batch) Test accuracy 계산 \n",
    "            predicted_classes = logits.softmax(dim=1).argmax(dim=1)\n",
    "            test_acc += metric(predicted_classes, y).item() # calculate the batch accuracy & add to the epoch accuracy\n",
    "\n",
    "    \n",
    "    # Batch 순회 종료 후\n",
    "    test_loss = test_loss / len(dataloader) # cost of batches / num of batches (calculate average)\n",
    "    test_acc  = test_acc  / len(dataloader) # acc  of batches / num of batches (calculate average)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(model, \n",
    "          train_dataloader, \n",
    "          test_dataloader, \n",
    "          optimizer, \n",
    "          loss_fn, \n",
    "          metric, \n",
    "          device, \n",
    "          epochs):\n",
    "    \n",
    "    results = {\"train_loss\": [], \n",
    "               \"train_acc\" : [], \n",
    "               \"test_loss\" : [], \n",
    "               \"test_acc\"  : []}\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)): # from tqdm.auto import tqdm\n",
    "        \n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn, \n",
    "                                           optimizer=optimizer, \n",
    "                                           metric=metric, \n",
    "                                           device=device)\n",
    "        \n",
    "        test_loss, test_acc   = test_step(model=model,\n",
    "                                          dataloader=test_dataloader, \n",
    "                                          loss_fn=loss_fn, \n",
    "                                          metric=metric, \n",
    "                                          device=device)\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        print('Epoch : {} | Train_loss : {} | Train_acc : {} | Test_loss : {} | Test_acc : {}'.format(epoch+1, \n",
    "                                                                                                      train_loss, \n",
    "                                                                                                      train_acc, \n",
    "                                                                                                      test_loss, \n",
    "                                                                                                      test_acc))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008c9f0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 4.  utils.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> Utility 함수들을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e59dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_module/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/utils.py\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def save_model(model, \n",
    "               target_dir,\n",
    "               model_name):\n",
    "\n",
    "    model_save_path = target_dir + '/' + model_name\n",
    "    \n",
    "    print(\"[INFO] Saving model to: {}\".format(model_save_path))\n",
    "    \n",
    "    torch.save(obj=model.state_dict(),\n",
    "               f=model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efac31e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# 5.  train.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> 모델 학습을 위한 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024ab1ad",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### * How to use [ **argparse** ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323e1ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArgumentParser' object has no attribute 'pars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      3\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpars\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ArgumentParser' object has no attribute 'pars'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686e0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_module/argparser_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/argparser_test.py\n",
    "\n",
    "import argparse # \"arg\"uments \"parse\"r\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Test for the argparser\")\n",
    "\n",
    "# \"test_number\"라는 이름의 argument를 받아내도록 세팅 <- default 30 & 'int' type \n",
    "parser.add_argument(\"--test_number\", \n",
    "                     default=30, \n",
    "                     type=int, \n",
    "                     help=\"set any integer to use\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "TEST_NUM = args.test_number # \"--test_number\"\n",
    "\n",
    "print('Selected number is {}'.format(TEST_NUM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff5d4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: argparser_test.py [-h] [--test_number TEST_NUMBER]\n",
      "\n",
      "Test for the argparser\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --test_number TEST_NUMBER\n",
      "                        set any integer to use\n"
     ]
    }
   ],
   "source": [
    "!python model_module/argparser_test.py --help\n",
    "\n",
    "# -h or --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db01a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number is 42\n"
     ]
    }
   ],
   "source": [
    "!python model_module/argparser_test.py --test_number 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c5d788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_module/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/train.py\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse # \"arg\"uments \"parse\"r\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy # PyTorch metrics\n",
    "\n",
    "import prepare_data, train_funcs, build_model, utils\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Argparser for hyper-parameters\")\n",
    "\n",
    "parser.add_argument(\"--num_epochs\", \n",
    "                     default=30, \n",
    "                     type=int, \n",
    "                     help=\"the number of epochs\")\n",
    "\n",
    "parser.add_argument(\"--batch_size\",\n",
    "                    default=32,\n",
    "                    type=int,\n",
    "                    help=\"number of samples per batch\")\n",
    "\n",
    "parser.add_argument(\"--num_filters\",\n",
    "                    default=32,\n",
    "                    type=int,\n",
    "                    help=\"number of filters to use in convolution layers\")\n",
    "\n",
    "parser.add_argument(\"--learning_rate\",\n",
    "                    default=0.001,\n",
    "                    type=float, # set the data type of the argument\n",
    "                    help=\"learning-rate\")\n",
    "\n",
    "parser.add_argument(\"--train_dir\",\n",
    "                    default=\"data_food101/data/train\",\n",
    "                    type=str, # set the data type of the argument\n",
    "                    help=\"directory path of training data\")\n",
    "\n",
    "parser.add_argument(\"--test_dir\",\n",
    "                    default=\"data_food101/data/test\",\n",
    "                    type=str, # set the data type of the argument\n",
    "                    help=\"directory path of testing data\")\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "NUM_EPOCHS = args.num_epochs\n",
    "BATCH_SIZE = args.batch_size\n",
    "NUM_FILTERS = args.num_filters\n",
    "LEARNING_RATE = args.learning_rate\n",
    "\n",
    "print(\"[INFO] Setup - Epochs : {} | Batch_size : {} | Num_filters : {} | Learning_rate : {}\".format(NUM_EPOCHS, \n",
    "                                                                                                    BATCH_SIZE, \n",
    "                                                                                                    NUM_FILTERS, \n",
    "                                                                                                    LEARNING_RATE))\n",
    "\n",
    "train_dir = args.train_dir\n",
    "test_dir = args.test_dir\n",
    "\n",
    "print(\"[INFO] Training directory : {}\".format(train_dir))\n",
    "print(\"[INFO] Testing directory : {}\".format(test_dir))\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # image resize\n",
    "    transforms.TrivialAugmentWide(num_magnitude_bins=31), # TrivialAugment\n",
    "    transforms.ToTensor() # (Original) PIL format -> PyTorch tensors \n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), # image resize\n",
    "    transforms.ToTensor() # (Original) PIL format -> PyTorch tensors \n",
    "])\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = prepare_data.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    train_transform=train_transform,\n",
    "    test_transform=test_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "\n",
    "model = build_model.CNNAugment_TinyVGG(num_channels=3, \n",
    "                                       num_filters=NUM_FILTERS, \n",
    "                                       num_classes=len(class_names)).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # Softmax + CrossEntropy (built-in Softmax)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), # \"parameters\" to optimize (apply gradient descent)\n",
    "                             lr=LEARNING_RATE)                  # \"l\"earning \"r\"ate \n",
    "    \n",
    "metric_accuracy = Accuracy(task='multiclass',\n",
    "                            num_classes=3).to(device) # from torchmetrics import Accuracy\n",
    "\n",
    "    \n",
    "train_funcs.train(model=model,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader,\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  metric=metric_accuracy,\n",
    "                  device=device,\n",
    "                  epochs=NUM_EPOCHS)\n",
    "\n",
    "\n",
    "utils.save_model(model=model,\n",
    "                 target_dir=\"model_module/models\",\n",
    "                 model_name=\"CNNAugment_TinyVGG_modular.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3d03959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python model_module/train.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ab2669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setup - Epochs : 1 | Batch_size : 32 | Num_filters : 32 | Learning_rate : 0.001\n",
      "[INFO] Training directory : data_food101/data/train\n",
      "[INFO] Testing directory : data_food101/data/test\n",
      "Unzipping the dataset.\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Epoch : 1 | Train_loss : 6.546626854687929 | Train_acc : 0.39453125 | Test_loss : 1.1514432231585185 | Test_acc : 0.2604166666666667\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "[INFO] Saving model to: model_module/models/CNNAugment_TinyVGG_modular.pth\n"
     ]
    }
   ],
   "source": [
    "!python model_module/train.py --num_epochs 1 --batch_size 32 --num_filters 32 --learning_rate 0.001\n",
    "\n",
    "# 종료 시점이 아닌 실시간으로 실행 결과를 확인하고 싶을 경우 cmd 창에서 실행 -> 10 epochs 이상 학습 진행 후 다음 cell의 이미지 예측 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa69449",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "# (Appendix)  predict_img.py\n",
    "\n",
    "<br>\n",
    "\n",
    "### -> 특정 이미지를 대상으로 한 Prediction을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5aa37d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_module/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_module/predict.py\n",
    "\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ? # to build a model\n",
    "\n",
    "\n",
    "parser = argparse.Arg?()\n",
    "\n",
    "parser.add_?(\"--image_path\",\n",
    "                    help=\"path of the image to predict on\")\n",
    "\n",
    "parser.add_?(\"--model_path\",\n",
    "                    default=\"model_module/models/CNNAugment_TinyVGG_modular.pth\",\n",
    "                    type=str,\n",
    "                    help=\"path of the saved model-parameters (.pth)\")\n",
    "\n",
    "\n",
    "args = parser.parse_?()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "IMG_PATH = args.?\n",
    "print(\"[INFO] Predicting on {}\".format(IMG_PATH))\n",
    "\n",
    "\n",
    "def load_model(file_path=args.?):\n",
    "    \n",
    "    model = build_model.?(num_channels=3, \n",
    "                                             num_filters=32, \n",
    "                                             num_classes=3).to(device)\n",
    "\n",
    "    print(\"[INFO] Loading model-parameters from: {}\".format(file_path))\n",
    "\n",
    "    model.?(torch.?(file_path)) # load -> load_state_dict\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_on_image(image_path=?, file_path=args.?):\n",
    "\n",
    "    model = ?(file_path) # Load the model\n",
    "\n",
    "    img_tensor = torchvision.io.read_?(IMG_PATH) # instead of [ ImageFolder & DataLoader ]\n",
    "    \n",
    "    img_tensor = img_tensor / 255.0\n",
    "    img_tensor = img_tensor.?(dim=0) # [Channels, Height, Width] -> [Batch_size, Channels, Height, Width]\n",
    "    \n",
    "    transform = torchvision.transforms.?(size=(64, 64)) # Don't need 'transforms.Compose'\n",
    "    img_tensor_transformed = transform(img_tensor) \n",
    "\n",
    "    \n",
    "    model.?()\n",
    "    \n",
    "    with torch.?():\n",
    "        \n",
    "        pred_logits = ?(img_tensor_transformed.?(device)) \n",
    "        \n",
    "        pred_prob = pred_logits.?(dim=1)\n",
    "        pred_prob_top = pred_prob.max(dim=1)[0].item()\n",
    "        \n",
    "        pred_label = pred_prob.?(dim=1)\n",
    "        pred_label_class = [\"pizza\", \"steak\", \"sushi\"][?]\n",
    "\n",
    "        print(\"[INFO] Predicted class: {}, Prediction probability: {:.3f}\".format(pred_label_class,\n",
    "                                                                                  pred_prob_top))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ?()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d64bc7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicting on data_food101/sample_pizza.jpg\n",
      "[INFO] Loading model-parameters from: model_module/models/CNNAugment_TinyVGG_modular.pth\n",
      "[INFO] Predicted class: sushi, Prediction probability: 0.493\n"
     ]
    }
   ],
   "source": [
    "!python model_module/predict.py --? data_food101/sample_pizza.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b50d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
