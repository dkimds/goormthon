{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# feasibility_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx2bHuJX4YbG"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkYNWvSjVhJE"
      },
      "source": [
        "\n",
        "## Finanacial sentiment analysis example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fdfa2e20265f4f28b0f9abb15d258b5e",
            "ba92a2711cef47f7a6936dad856b87fe",
            "1da503de60754ac589ee9e860e9a32ea",
            "a4375878c7f3472e8bcde5eb3336db4e",
            "8b01dcbcfef44ff3b789273892f77685",
            "4d7dcd9b150e467aaaa70d8766f1e27a",
            "82ac5f0e6e394c72a284e9d7b7f43b12",
            "62bc8f7f6ff843c4837219fd751f7245",
            "3471dbd7b2e74e8cbb17ecd0220c3514",
            "e94876988bc64a8eb31001d8f4ad3757",
            "6d51b676681f4418b242972dcf52b853",
            "c5b9aa0584574f3d91427e4e6cf97027",
            "01e55c6f0f8945eaba683be37e82450e",
            "a08a16f3a1fc4363aa2f902b657aec39",
            "c864300f968844e0849943e5a5363d9d",
            "9d91e56f6c594bd4b6ee0e10452e510f",
            "e08aa8a6ee7943ccbbe87d859df29b81",
            "91b8c9cdc52543d0b24a414054f5d149",
            "3971aa4cf0694951b3e5a6b0a4bd2c85",
            "f728b63690ce41abb99a7b25add1d1dd",
            "cda4898fa533464cbfb29397952eb0d8",
            "b682b10c52d94ef9ae2964d1265fd430",
            "3995376bd67e4509a9cc96db86d1f7fb",
            "532119820fc349259d0875bafdb137f0",
            "1ae59170c307467da03051a97b4aa3be",
            "0b2f6b4365314973979c9ee85dd21c0d",
            "38a8f72774054198afe2d938fedddda4",
            "dc4b47e06e2a41028c5eb581e9caa813",
            "f90b4ba1ddc4419681c9d3969cf0700d",
            "ee7f07956e704b188012d428ad671e55",
            "48721bc0f245437c9da9fc2e13385116",
            "b09e2c8c0687439e80dae3b314218e0c",
            "99f1645125b34f97904935c6a651c010",
            "331a99ddbecd43878db1186b19721c5f",
            "ab88f540adda404e96beee852cd6acb6",
            "dd0a9c7b9a654abca1a8fbd67524922e",
            "442d0138f6124f1ab9c8ae83e06acbbf",
            "0086f1c20aaf40ae9335ab30eac49a66",
            "42ce3a94e82c416b97868bfb19b0b643",
            "a80744296b0c45c9989c381e8363cf3b",
            "2ea46188f7fb425688edb821d2b6bcef",
            "bf56d791b4be40db88ec4c799fc90339",
            "0963801176fb41dea0214d076b183fc5",
            "c4231bd6ec8d4c399e0499c151058e2d",
            "aebb1dd034db42c8b83246192383d36d",
            "a5f36f6996b744f5b1fcca012dbd1887",
            "4073085449884e2f919f782830c8fe52",
            "36e3f80703824f039c5e0fe7e19e196a",
            "b637b08291dc47aa8408bb4aaece4c45",
            "88708b44d92f4a1ab3dc06fba99cc34c",
            "3e91cfe27ebf42888ce6044f948fc973",
            "fe4aecb9c109484cb4c8e8940da4b887",
            "30cbe99066d747b3959775cd5b47a2f8",
            "355ca9c881f14b29a65b4a130f18a920",
            "0ec0ef49fedf4a12b3f1f0e5085d9002",
            "f1838c9575f64f798ce42fc43a376373",
            "333d97c5086848f5bc49b93f9e417009",
            "d5645698dc5440c79acc19ad64de0a32",
            "53752c6ad6a24f31a3c207a6a2ed3a96",
            "2b911ea3f9c9435699989493bbd9a6ac",
            "3ae93093bc204a32b2927b7baf486350",
            "72def5344584474bbde6de3b6f956dfe",
            "9b761bfdb9164372ac30e969bddb2b54",
            "1fb37831a47f4f94bcf531d84f132172",
            "ad4e3a6720594bc6888940f24b5520d8",
            "449b0058bb554e2a84320aff82419afc"
          ]
        },
        "id": "HZ9-snMHWTSU",
        "outputId": "d481a9ca-2861-4936-dd2a-0e9710176c8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdfa2e20265f4f28b0f9abb15d258b5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/992 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5b9aa0584574f3d91427e4e6cf97027",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaModel were not initialized from the model checkpoint at Hyeonseo/ko-finance_news_classifier and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3995376bd67e4509a9cc96db86d1f7fb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/471 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "331a99ddbecd43878db1186b19721c5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aebb1dd034db42c8b83246192383d36d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1838c9575f64f798ce42fc43a376373",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁카', '카', '오', '뱅', '크', '와', '▁에', '프', '엔', '가', '이드', '가', '▁금융', '특', '화', '▁언어', '모델', '을', '▁공개', '합니다', '.']\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.8885,  0.0885, -0.1120,  ...,  0.3273,  0.0130, -0.0763],\n",
            "         [ 0.5194, -0.0821, -0.2574,  ...,  1.9207, -0.2241,  0.1289],\n",
            "         [ 0.4305,  0.0797, -0.1494,  ...,  2.1106, -0.1999, -0.0026],\n",
            "         ...,\n",
            "         [ 0.4004, -0.2475, -0.0969,  ...,  1.6254, -0.0999,  0.6483],\n",
            "         [ 0.5771, -0.1590,  0.0382,  ...,  1.1515, -0.0720,  0.5959],\n",
            "         [ 0.8929,  0.0934, -0.1111,  ...,  0.3322,  0.0120, -0.0752]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.2718,  0.3632, -0.1319, -0.7271, -0.1444, -0.6216, -0.0051,  0.6422,\n",
            "          0.4543,  0.0081, -0.2847, -0.0755,  0.4755, -0.4839, -0.0456,  0.0320,\n",
            "          0.1258, -0.0050,  0.0399, -0.0017, -0.6468, -0.1238, -0.3350,  0.1769,\n",
            "         -0.4225, -0.3993,  0.3345, -0.2854, -0.5096,  0.3208,  0.3147, -0.1424,\n",
            "          0.2746,  0.1932,  0.3045,  0.2031, -0.0096, -0.1530, -0.3537,  0.0936,\n",
            "          0.0605,  0.2514, -0.4996, -0.1263,  0.0167, -0.1992, -0.3280, -0.3104,\n",
            "          0.2713, -0.3738,  0.0959, -0.5024, -0.1435, -0.0404,  0.1171,  0.4218,\n",
            "          0.2801, -0.4741,  0.4119, -0.2888,  0.1592, -0.2337, -0.4680,  0.4773,\n",
            "          0.3048, -0.0653, -0.4018, -0.2251,  0.2238, -0.1125,  0.0680,  0.2425,\n",
            "          0.1602, -0.2427, -0.3383, -0.4895,  0.0498, -0.0095,  0.2686, -0.4360,\n",
            "         -0.0670, -0.2396, -0.0620,  0.1382, -0.2065, -0.0198, -0.6269, -0.3528,\n",
            "         -0.0326,  0.2884, -0.1042,  0.1261,  0.3246,  0.1016, -0.2354,  0.1073,\n",
            "         -0.1821,  0.6558, -0.1132,  0.1506, -0.3646,  0.0274, -0.2402,  0.2966,\n",
            "         -0.1601,  0.1754,  0.0892,  0.2964,  0.4879,  0.4517,  0.3581,  0.3715,\n",
            "          0.5567, -0.2471, -0.0909, -0.0800,  0.1803, -0.3688,  0.0805,  0.3594,\n",
            "          0.2539, -0.0012, -0.0199, -0.0443, -0.0629,  0.1370, -0.3715, -0.2802,\n",
            "          0.4933,  0.2440, -0.5389,  0.1062,  0.3375,  0.3049,  0.3437,  0.0483,\n",
            "         -0.6345,  0.1252, -0.1074, -0.0966, -0.0188,  0.1294,  0.0278,  0.4495,\n",
            "         -0.4443, -0.1709,  0.3656,  0.3375, -0.2821, -0.5413,  0.3891,  0.5297,\n",
            "          0.2206, -0.0213,  0.1867, -0.4619,  0.3406, -0.4806,  0.2127, -0.3759,\n",
            "          0.3420,  0.1106,  0.3144,  0.8590, -0.2210,  0.1503,  0.5988, -0.0383,\n",
            "          0.3038, -0.1134,  0.0141,  0.0463, -0.3754,  0.1296,  0.3213,  0.1475,\n",
            "          0.2585,  0.3465, -0.1023,  0.0479, -0.3089,  0.4208, -0.5292,  0.5522,\n",
            "         -0.1806, -0.1155, -0.1396,  0.1625, -0.4336, -0.2757, -0.1154,  0.0140,\n",
            "         -0.6163, -0.2205, -0.4472, -0.1309, -0.5309,  0.2252,  0.6552, -0.3064,\n",
            "         -0.0848,  0.4249,  0.0145, -0.3086,  0.3647,  0.2068, -0.4459,  0.5398,\n",
            "         -0.1985, -0.1143,  0.0971, -0.5276,  0.3169,  0.3279,  0.6501,  0.1037,\n",
            "         -0.3384,  0.0374, -0.2590, -0.2562, -0.2763, -0.1930, -0.3947,  0.2095,\n",
            "          0.3623,  0.3290,  0.1985,  0.4699, -0.4149, -0.6582,  0.1903,  0.2076,\n",
            "          0.1343,  0.3953,  0.3731, -0.0055, -0.0115, -0.6365,  0.0999, -0.1777,\n",
            "         -0.1691, -0.2560, -0.2863, -0.2124, -0.0940, -0.4931, -0.1540, -0.4820,\n",
            "          0.3404,  0.0035, -0.4564,  0.3411, -0.0740, -0.2152,  0.2867, -0.1552,\n",
            "         -0.2840,  0.2835, -0.5597,  0.2709, -0.1094,  0.0238,  0.1227,  0.3898,\n",
            "          0.0730, -0.0296,  0.2522,  0.3518,  0.0322,  0.2584, -0.2866,  0.4116,\n",
            "         -0.0441, -0.2236,  0.1585,  0.2662,  0.0382, -0.1983,  0.1978,  0.3857,\n",
            "          0.4160, -0.4392, -0.1314, -0.3935,  0.1799, -0.2794,  0.0903,  0.3910,\n",
            "          0.1344,  0.3565, -0.0732,  0.0770, -0.2797,  0.5583,  0.0434,  0.5990,\n",
            "         -0.3171, -0.3361, -0.0427, -0.1895,  0.2801, -0.2207, -0.1077,  0.2589,\n",
            "          0.0649, -0.4051, -0.0508,  0.0474,  0.1285, -0.3248, -0.1192,  0.7721,\n",
            "         -0.0393,  0.2397,  0.2665,  0.0869, -0.0463, -0.4361, -0.4638,  0.1255,\n",
            "          0.1855,  0.1250, -0.3617, -0.7167, -0.2485, -0.0050,  0.5790, -0.0278,\n",
            "          0.2824,  0.0974, -0.1114,  0.1844, -0.4954, -0.5375,  0.1779,  0.0193,\n",
            "          0.5751, -0.0864,  0.1963, -0.0399,  0.6160,  0.2118,  0.4005, -0.3268,\n",
            "          0.1923, -0.1359, -0.0362, -0.3276, -0.3520, -0.2913,  0.0609, -0.2640,\n",
            "          0.2672, -0.2961,  0.3733,  0.0612, -0.2910,  0.1851,  0.5611,  0.1695,\n",
            "         -0.1516, -0.0254,  0.0747, -0.0291, -0.6400, -0.3710, -0.3396,  0.1732,\n",
            "          0.4064,  0.0519,  0.0487, -0.0451, -0.2139, -0.0245, -0.0861,  0.0317,\n",
            "         -0.0239,  0.5783,  0.3558,  0.6096,  0.2850, -0.1052, -0.3782, -0.3729,\n",
            "          0.1713,  0.2692, -0.1985,  0.0875,  0.4923, -0.0786,  0.4036,  0.1210,\n",
            "         -0.3047, -0.0687,  0.1135,  0.4816,  0.4907,  0.0012, -0.4349,  0.3701,\n",
            "         -0.3604,  0.2354,  0.4277, -0.1886, -0.2483,  0.3573, -0.1755,  0.3305,\n",
            "         -0.5460,  0.7405,  0.0220, -0.0787, -0.0786, -0.0456, -0.1684,  0.0086,\n",
            "          0.0846,  0.4893, -0.3344, -0.0083,  0.1692,  0.3170, -0.0196, -0.1119,\n",
            "          0.5478,  0.1277, -0.4958,  0.0760, -0.0398,  0.0344,  0.4830, -0.4004,\n",
            "          0.4581, -0.1827, -0.0287, -0.2035, -0.5748,  0.2572,  0.1713, -0.0320,\n",
            "          0.0232, -0.1557, -0.4489,  0.3402, -0.2852, -0.4839, -0.1634,  0.4144,\n",
            "         -0.0978,  0.1046,  0.2627,  0.3670, -0.1527, -0.1686,  0.0359, -0.0325,\n",
            "         -0.2910,  0.4125, -0.2991,  0.0276, -0.4357, -0.2649, -0.2435,  0.0704,\n",
            "         -0.3612,  0.0318,  0.1732,  0.3237, -0.4151,  0.6286,  0.0777,  0.1564,\n",
            "          0.0993, -0.3492, -0.0369, -0.2134, -0.0763, -0.4581, -0.1222, -0.4254,\n",
            "          0.4190, -0.0641,  0.3369,  0.3058,  0.2640, -0.6344,  0.2425, -0.2477,\n",
            "          0.4185,  0.2546,  0.3274, -0.2809,  0.0320, -0.1842, -0.2235,  0.5066,\n",
            "          0.1199, -0.0234,  0.6288, -0.0212, -0.1451, -0.0466, -0.3611,  0.0457,\n",
            "          0.0399,  0.5204,  0.3205,  0.3587,  0.1209, -0.5910, -0.0203,  0.2097,\n",
            "          0.0474, -0.6924, -0.4055,  0.3657, -0.1319,  0.6602,  0.1144, -0.2619,\n",
            "          0.4353,  0.0938, -0.1733, -0.3208,  0.3099, -0.0885,  0.0032,  0.3807,\n",
            "         -0.3152,  0.0284,  0.1387,  0.0308, -0.0708, -0.3082,  0.2194, -0.0446,\n",
            "         -0.0970,  0.3973, -0.1947,  0.4571, -0.3858,  0.3142, -0.3442, -0.2634,\n",
            "         -0.5046, -0.3289, -0.3193,  0.0697,  0.0943, -0.7496,  0.8068,  0.0318,\n",
            "         -0.1890,  0.2398, -0.3067,  0.3288,  0.0619, -0.2567, -0.3888,  0.5373,\n",
            "         -0.3050,  0.1546, -0.0708, -0.2825, -0.2404, -0.5633, -0.6645,  0.0694,\n",
            "         -0.2918,  0.2964, -0.0487, -0.0474,  0.0605,  0.0806, -0.0947,  0.2403,\n",
            "          0.0358,  0.0560, -0.2526,  0.0097,  0.1387, -0.0601,  0.0603,  0.1467,\n",
            "         -0.2071,  0.2105,  0.0153, -0.0130,  0.5327,  0.0511,  0.3287,  0.5090,\n",
            "         -0.0575, -0.2439, -0.2584, -0.5202,  0.5301, -0.4637, -0.5295,  0.1198,\n",
            "         -0.1713,  0.1269,  0.1852, -0.0332, -0.0232, -0.5815,  0.1464, -0.3447,\n",
            "          0.5731,  0.0870, -0.1625,  0.1680,  0.0503,  0.4179,  0.4069,  0.3380,\n",
            "         -0.3300,  0.2460, -0.1776,  0.2755, -0.0134, -0.5064,  0.4074, -0.0928,\n",
            "         -0.4544,  0.0563, -0.2086, -0.2726,  0.1891,  0.3916,  0.0646,  0.2644,\n",
            "         -0.3251, -0.1372,  0.0921,  0.5047, -0.0125,  0.5044,  0.3695,  0.0583,\n",
            "         -0.0315, -0.3763,  0.2890, -0.4150, -0.1262, -0.2690,  0.5738,  0.3634,\n",
            "         -0.2564, -0.0022,  0.1113, -0.6160, -0.0748, -0.3125,  0.5050,  0.0304,\n",
            "          0.4961,  0.4261,  0.0777,  0.2069, -0.0411,  0.1825, -0.3908, -0.6505,\n",
            "         -0.2811, -0.4889, -0.3546, -0.2777,  0.2100,  0.0550, -0.2121,  0.3496,\n",
            "         -0.0235,  0.4172, -0.2461, -0.3704, -0.1243,  0.0037, -0.0310, -0.2285,\n",
            "         -0.2840,  0.3827, -0.4915,  0.1780, -0.0756, -0.1386, -0.3436, -0.0721,\n",
            "         -0.3179, -0.6678,  0.2470,  0.0323,  0.0609,  0.2607, -0.0219, -0.2778,\n",
            "          0.4547, -0.5907,  0.0767,  0.0424, -0.1279, -0.0881,  0.1046, -0.2404,\n",
            "          0.2348, -0.0022,  0.1161, -0.4358,  0.1525, -0.3758,  0.0432,  0.2310,\n",
            "         -0.0048,  0.1994,  0.0019,  0.3905,  0.1728,  0.0080,  0.0456, -0.2115,\n",
            "          0.4035,  0.1555, -0.0994, -0.3347,  0.0664,  0.0012,  0.0253, -0.5073,\n",
            "         -0.3301, -0.1094,  0.0278, -0.2040, -0.0706,  0.0554,  0.0704,  0.5072,\n",
            "          0.2904,  0.1118,  0.0738, -0.0964,  0.0724, -0.4899, -0.4017, -0.3202,\n",
            "          0.1881,  0.3112,  0.4263, -0.4371, -0.2530, -0.1652, -0.3404, -0.0645,\n",
            "          0.0768, -0.1588,  0.2893,  0.2716,  0.0336, -0.2872,  0.5624, -0.4321,\n",
            "          0.0967, -0.4175, -0.4137,  0.0364,  0.6026,  0.5174, -0.0536,  0.1407]],\n",
            "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "checkpoint = \"Hyeonseo/ko-finance_news_classifier\"\n",
        "model = AutoModel.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "text = \"카카오뱅크와 에프엔가이드가 금융특화 언어모델을 공개합니다.\"\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "model_output = model(**inputs)\n",
        "print(model_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVoRpH6UWiZ1"
      },
      "source": [
        "## Sentiment analysis pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqjGeR42XRnD",
        "outputId": "64c8f52b-7408-4557-d118-c29733aba351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9994926452636719},\n",
              " {'label': 'negative', 'score': 0.9993537068367004},\n",
              " {'label': 'neutral', 'score': 0.9994351267814636}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "raw_inputs = [\n",
        "        \"신세계백화점이 지난해 역대 최대 매출을 올렸다.\",\n",
        "        \"국내 최대 컨테이너 선사인 HMM 매각 협상이 6일 최종 결렬되면서 산업은행이 고심에 빠졌다.\",\n",
        "        \"카카오뱅크와 에프엔가이드가 금융특화 언어모델을 공개합니다.\",\n",
        "]\n",
        "classifier = pipeline(\"sentiment-analysis\", model=checkpoint)\n",
        "classifier(raw_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryPUN-GYCfvq"
      },
      "source": [
        "부정/긍정/중립 출력확인\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US_k_VIH4lPG"
      },
      "source": [
        "## Keyword extraction pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFUjnvRo9G-1",
        "outputId": "73513d2f-0645-46c6-9013-50ca4a729374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'entity': 'B-LC', 'score': 0.96574193, 'index': 1, 'word': '서울역', 'start': 0, 'end': 3}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Leo97/KoELECTRA-small-v3-modu-ner\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"Leo97/KoELECTRA-small-v3-modu-ner\")\n",
        "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "# pipeline\n",
        "example = \"서울역으로 안내해줘.\"\n",
        "ner_results = ner(example)\n",
        "print(ner_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzMXuP8e7Jk4",
        "outputId": "6e646f8a-8e09-445e-de56-f625366ff127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(ner_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisiGxH2CYYz"
      },
      "source": [
        "회사명만 추출, H는 HMM 앞글자만 나옴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVOf2IUJ6tDZ",
        "outputId": "23356cf4-1ee0-41a1-c60f-0931bf19bd6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entity': 'B-OG',\n",
              "  'score': 0.9761239,\n",
              "  'index': 1,\n",
              "  'word': '신세계백화점',\n",
              "  'start': 0,\n",
              "  'end': 6},\n",
              " {'entity': 'B-OG',\n",
              "  'score': 0.8577335,\n",
              "  'index': 6,\n",
              "  'word': 'H',\n",
              "  'start': 15,\n",
              "  'end': 16},\n",
              " {'entity': 'B-OG',\n",
              "  'score': 0.9703011,\n",
              "  'index': 1,\n",
              "  'word': '카카오',\n",
              "  'start': 0,\n",
              "  'end': 3}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner_results = ner(raw_inputs)\n",
        "og = []\n",
        "for result in ner_results:\n",
        "    og.append(result['entity'in ['B-OG']])\n",
        "\n",
        "og"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdMS3aCQ-i31"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
