{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTS-RX0XNdJF"
      },
      "source": [
        "# 한국어 word2vec 작성\n",
        "\n",
        "- CBOW, window size 2 의 simplified word2vec model 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3XXscvEafNs"
      },
      "outputs": [],
      "source": [
        "# Install konlpy\n",
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wC6_rxXQXWq"
      },
      "outputs": [],
      "source": [
        "# Install Korean fonts\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "세션을 재시작하시오."
      ],
      "metadata": {
        "id": "Nrt5pHhVxYHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IdNzusOZNdJH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAyFLxJyNdJI"
      },
      "source": [
        "### Toy 말뭉치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ROpJ63O9NdJI"
      },
      "outputs": [],
      "source": [
        "corpus = ['왕은 매우 강한 남자이다',\n",
        "          '여왕은 현명한 예쁜 여자이다',\n",
        "          '소년은 젊은 남자이다',\n",
        "          '소녀는 젊은 예쁜 여자이다',\n",
        "          '왕자는 젊고 현명한 왕이 될 것이다',\n",
        "          '공주는 젊고 예쁜 현명한 여왕이 될 것이다',\n",
        "          '남자는 강하다',\n",
        "          '여자는 예쁘다',\n",
        "          '왕자는 왕이 될 소년이다',\n",
        "          '공주는 왕비가 될 소녀이다']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l-9me-_NdJJ",
        "outputId": "36a22ad6-f3b0-4663-fb55-9485e6a72bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "왕은 매우 강한 남자이다\n",
            "여왕은 현명한 예쁜 여자이다\n",
            "소년은 젊은 남자이다\n",
            "소녀는 젊은 예쁜 여자이다\n",
            "왕자는 젊고 현명한 왕이 될 것이다\n",
            "공주는 젊고 예쁜 현명한 여왕이 될 것이다\n",
            "남자는 강하다\n",
            "여자는 예쁘다\n",
            "왕자는 왕이 될 소년이다\n",
            "공주는 왕비가 될 소녀이다\n"
          ]
        }
      ],
      "source": [
        "cleaned_corpus = []\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "    text = re.sub(r'[^a가-힣]', '', text)  #한글\n",
        "    cleaned_corpus.append(text.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ID2G0kNdJJ"
      },
      "source": [
        "### stopword 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EPlKopmNdJK",
        "outputId": "98376abb-80c1-45ac-b59f-4d6d6bf06f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Okt.morphs of <konlpy.tag._okt.Okt object at 0x7e6c688ebdc0>>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "okt.morphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ijg4GRBTNdJK"
      },
      "outputs": [],
      "source": [
        "stop_words = ['은', '가', '이다', '는', '이', '될']\n",
        "\n",
        "results = []\n",
        "\n",
        "for text in corpus:\n",
        "    tmp = []\n",
        "    for word in okt.morphs(text):\n",
        "        if word not in stop_words:\n",
        "            tmp.append(word)\n",
        "    results.append(' '.join(tmp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9nXQuw2NdJK",
        "outputId": "73d6ef65-b66c-4d0f-e4e9-af22205dda75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['왕 매우 강한 남자',\n",
              " '여왕 현명한 예쁜 여자',\n",
              " '소년 젊은 남자',\n",
              " '소녀 젊은 예쁜 여자',\n",
              " '왕자 젊고 현명한 왕 것',\n",
              " '공주 젊고 예쁜 현명한 여왕 것',\n",
              " '남자 강하다',\n",
              " '여자 예쁘다',\n",
              " '왕자 왕 소년',\n",
              " '공주 왕비 소녀']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "cleaned_corpus = results\n",
        "cleaned_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iko9aUJNdJL"
      },
      "source": [
        "### vocaburary 모음 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erhHSb16NdJL",
        "outputId": "812762c6-8943-4b86-a525-363a3b7d87c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['소년',\n",
              " '현명한',\n",
              " '것',\n",
              " '남자',\n",
              " '왕자',\n",
              " '공주',\n",
              " '왕',\n",
              " '여자',\n",
              " '젊고',\n",
              " '강한',\n",
              " '강하다',\n",
              " '여왕',\n",
              " '예쁜',\n",
              " '소녀',\n",
              " '젊은',\n",
              " '왕비',\n",
              " '예쁘다',\n",
              " '매우']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "words = []\n",
        "\n",
        "for sentence in cleaned_corpus:\n",
        "    for word in sentence.split(' '):\n",
        "        words.append(word)\n",
        "\n",
        "words = list(set(words))\n",
        "words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpPni9I3NdJL"
      },
      "source": [
        "### word-to-index, index-to-word 작성\n",
        "\n",
        "- word 를 index 로 변환  \n",
        "\n",
        "- sentence 를 word index 로 변환  \n",
        "\n",
        "- window size 에 따라 train data 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "enx1Sy5gNdJL"
      },
      "outputs": [],
      "source": [
        "word2index = dict((w, i) for i, w in enumerate(words))\n",
        "index2word = dict((i, w) for i, w in enumerate(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57n1x1qcNdJM",
        "outputId": "2fada0c7-9058-4ace-df97-31b948fba046"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'소년': 0,\n",
              " '현명한': 1,\n",
              " '것': 2,\n",
              " '남자': 3,\n",
              " '왕자': 4,\n",
              " '공주': 5,\n",
              " '왕': 6,\n",
              " '여자': 7,\n",
              " '젊고': 8,\n",
              " '강한': 9,\n",
              " '강하다': 10,\n",
              " '여왕': 11,\n",
              " '예쁜': 12,\n",
              " '소녀': 13,\n",
              " '젊은': 14,\n",
              " '왕비': 15,\n",
              " '예쁘다': 16,\n",
              " '매우': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "word2index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QSsOL1dNdJM"
      },
      "source": [
        "### CBOW 로 training data 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ3t2gBLNdJM",
        "outputId": "87ff435f-18a0-482c-bfbc-17bea54e78b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['왕', '매우', '강한', '남자'],\n",
              " ['여왕', '현명한', '예쁜', '여자'],\n",
              " ['소년', '젊은', '남자'],\n",
              " ['소녀', '젊은', '예쁜', '여자'],\n",
              " ['왕자', '젊고', '현명한', '왕', '것'],\n",
              " ['공주', '젊고', '예쁜', '현명한', '여왕', '것'],\n",
              " ['남자', '강하다'],\n",
              " ['여자', '예쁘다'],\n",
              " ['왕자', '왕', '소년'],\n",
              " ['공주', '왕비', '소녀']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sentences = []\n",
        "for sentence in cleaned_corpus:\n",
        "    sentences.append(sentence.split())\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IRPTmtxGNdJM"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] :\n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZQ3L69NdJM",
        "outputId": "072e6b29-6f5a-4598-d356-51469b6ca31b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['왕', '매우'],\n",
              " ['왕', '강한'],\n",
              " ['매우', '왕'],\n",
              " ['매우', '강한'],\n",
              " ['매우', '남자'],\n",
              " ['강한', '왕'],\n",
              " ['강한', '매우'],\n",
              " ['강한', '남자'],\n",
              " ['남자', '매우'],\n",
              " ['남자', '강한']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "skip-gram과 CBOW의 차이점은 인풋과 라벨의 순서를 반대로 바꿔주는 것이다."
      ],
      "metadata": {
        "id": "_i6r6YS2y7lK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5-ZnifbvNdJM",
        "outputId": "704d0fb3-a50c-491b-ada8-54d7202460fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label input\n",
              "0     왕    매우\n",
              "1     왕    강한\n",
              "2    매우     왕\n",
              "3    매우    강한\n",
              "4    매우    남자"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e08769a3-0c56-481e-967b-023d5cc3147c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>왕</td>\n",
              "      <td>매우</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>왕</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>매우</td>\n",
              "      <td>왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>매우</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>매우</td>\n",
              "      <td>남자</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e08769a3-0c56-481e-967b-023d5cc3147c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e08769a3-0c56-481e-967b-023d5cc3147c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e08769a3-0c56-481e-967b-023d5cc3147c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e757ed00-a21b-45e5-8b8f-b0abb223dc86\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e757ed00-a21b-45e5-8b8f-b0abb223dc86')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e757ed00-a21b-45e5-8b8f-b0abb223dc86 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['label', 'input'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lom09YKYNdJN"
      },
      "source": [
        "### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMftiqg0NdJN",
        "outputId": "1a9e6425-03b9-4571-b760-bbed054de90b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4aGj-0NdJN"
      },
      "source": [
        "### One hot encoding 된 train, label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "it0xjkFmNdJN"
      },
      "outputs": [],
      "source": [
        "X = [] # input word\n",
        "Y = [] # target word\n",
        "\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    X.append(to_categorical(word2index[x], len(words)))\n",
        "    Y.append(to_categorical(word2index[x], len(words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsIERp49NdJN",
        "outputId": "a70473f7-4130-42be-9863-99a62477e45a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32)]\n",
            "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(X[:3])\n",
        "print(Y[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "P2Obs9yFNdJN"
      },
      "outputs": [],
      "source": [
        "# convert them to numpy arrays\n",
        "X_train = np.array(X)\n",
        "Y_train = np.array(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ab9QTmDNdJN"
      },
      "source": [
        "**시각화를 위해 hidden layer 의 unit 을 2 로 제한**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PAtqd6iaNdJN"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=len(words)))\n",
        "model.add(Dense(len(words)))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfFvzj9tNdJN",
        "outputId": "eeb51a64-3a63-427c-8296-4986827260d7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 4.9650 - accuracy: 0.0119 \n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 5.4947 - accuracy: 0.0595\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 5.8641 - accuracy: 0.0595\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 4.8058 - accuracy: 0.0595\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 6.3513 - accuracy: 0.0595    \n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8282 - accuracy: 0.0595 \n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 9ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6bc450f7f0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs=500, batch_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBm9JWQyNdJN"
      },
      "source": [
        "### 첫번째 Hidden Layer 추출 및 weight + bias 를 vector 로 합산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaLL_1xHNdJN",
        "outputId": "41c80ce5-ad03-4ec4-c471-118f4eb2dc18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2)                 38        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                54        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92 (368.00 Byte)\n",
            "Trainable params: 92 (368.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVVWbleNdJO",
        "outputId": "21aa3f19-7dd3-4c70-c3ca-696ac8a00e80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.07991884,  0.45559525],\n",
              "        [ 0.55792356,  0.28252584],\n",
              "        [-0.14378543, -0.05061423],\n",
              "        [ 0.5531177 , -0.08560189],\n",
              "        [ 0.40152496,  0.44734973],\n",
              "        [ 0.15297276, -0.31902266],\n",
              "        [-0.37556025, -0.31404105],\n",
              "        [-0.35905296,  0.00718742],\n",
              "        [ 0.18037415,  0.02160347],\n",
              "        [ 0.49849617, -0.41262153],\n",
              "        [-0.26172408, -0.22816081],\n",
              "        [-0.26323205,  0.47246045],\n",
              "        [ 0.18599282, -0.5192698 ],\n",
              "        [-0.20204976,  0.17797166],\n",
              "        [-0.16526797, -0.46528098],\n",
              "        [ 0.38084984, -0.15414804],\n",
              "        [-0.09870271,  0.49148402],\n",
              "        [-0.06107356, -0.34182853]], dtype=float32),\n",
              " array([-0.01993631,  0.00784895], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.layers[0].get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5qIPzp6NdJO",
        "outputId": "e2ac1918-b2de-4323-e5f5-d89da7e4e91f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.05998253,  0.4634442 ],\n",
              "       [ 0.53798723,  0.2903748 ],\n",
              "       [-0.16372174, -0.04276528],\n",
              "       [ 0.53318137, -0.07775294],\n",
              "       [ 0.38158864,  0.45519868]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "vectors= model.layers[0].get_weights()[0] + model.layers[0].get_weights()[1]\n",
        "vectors[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8AbOvoHNdJO",
        "outputId": "41eb5650-4691-4ff5-b14c-6a2b2d60ecf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['소년',\n",
              " '현명한',\n",
              " '것',\n",
              " '남자',\n",
              " '왕자',\n",
              " '공주',\n",
              " '왕',\n",
              " '여자',\n",
              " '젊고',\n",
              " '강한',\n",
              " '강하다',\n",
              " '여왕',\n",
              " '예쁜',\n",
              " '소녀',\n",
              " '젊은',\n",
              " '왕비',\n",
              " '예쁘다',\n",
              " '매우']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "OBgTTD04NdJO",
        "outputId": "5e656f11-a0b5-4c2a-e77c-e50e93cd6e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          x1        x2 word\n",
              "0   0.059983  0.463444   소년\n",
              "1   0.537987  0.290375  현명한\n",
              "2  -0.163722 -0.042765    것\n",
              "3   0.533181 -0.077753   남자\n",
              "4   0.381589  0.455199   왕자\n",
              "5   0.133036 -0.311174   공주\n",
              "6  -0.395497 -0.306192    왕\n",
              "7  -0.378989  0.015036   여자\n",
              "8   0.160438  0.029452   젊고\n",
              "9   0.478560 -0.404773   강한\n",
              "10 -0.281660 -0.220312  강하다\n",
              "11 -0.283168  0.480309   여왕\n",
              "12  0.166057 -0.511421   예쁜\n",
              "13 -0.221986  0.185821   소녀\n",
              "14 -0.185204 -0.457432   젊은\n",
              "15  0.360914 -0.146299   왕비\n",
              "16 -0.118639  0.499333  예쁘다\n",
              "17 -0.081010 -0.333980   매우"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fea96a6f-6675-4fe7-938f-d52777e5433f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.059983</td>\n",
              "      <td>0.463444</td>\n",
              "      <td>소년</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.537987</td>\n",
              "      <td>0.290375</td>\n",
              "      <td>현명한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.163722</td>\n",
              "      <td>-0.042765</td>\n",
              "      <td>것</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.533181</td>\n",
              "      <td>-0.077753</td>\n",
              "      <td>남자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.381589</td>\n",
              "      <td>0.455199</td>\n",
              "      <td>왕자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.133036</td>\n",
              "      <td>-0.311174</td>\n",
              "      <td>공주</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.395497</td>\n",
              "      <td>-0.306192</td>\n",
              "      <td>왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.378989</td>\n",
              "      <td>0.015036</td>\n",
              "      <td>여자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.160438</td>\n",
              "      <td>0.029452</td>\n",
              "      <td>젊고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.478560</td>\n",
              "      <td>-0.404773</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.281660</td>\n",
              "      <td>-0.220312</td>\n",
              "      <td>강하다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.283168</td>\n",
              "      <td>0.480309</td>\n",
              "      <td>여왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.166057</td>\n",
              "      <td>-0.511421</td>\n",
              "      <td>예쁜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.221986</td>\n",
              "      <td>0.185821</td>\n",
              "      <td>소녀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.185204</td>\n",
              "      <td>-0.457432</td>\n",
              "      <td>젊은</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.360914</td>\n",
              "      <td>-0.146299</td>\n",
              "      <td>왕비</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-0.118639</td>\n",
              "      <td>0.499333</td>\n",
              "      <td>예쁘다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.081010</td>\n",
              "      <td>-0.333980</td>\n",
              "      <td>매우</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fea96a6f-6675-4fe7-938f-d52777e5433f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fea96a6f-6675-4fe7-938f-d52777e5433f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fea96a6f-6675-4fe7-938f-d52777e5433f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a56fa31c-3817-436d-9f0f-52d5fe76d81f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a56fa31c-3817-436d-9f0f-52d5fe76d81f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a56fa31c-3817-436d-9f0f-52d5fe76d81f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f8746635-dad0-4032-b1ad-301288f2716f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('w2v')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8746635-dad0-4032-b1ad-301288f2716f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('w2v');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "w2v = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v['word'] = words\n",
        "w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "MdFfXRIZNdJO",
        "outputId": "8c76eb9c-ec2c-479a-f3c9-980b98d499a6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False               #한글사용시 마이너스 사인 깨짐 방지\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "for word, x1, x2 in zip(w2v['word'], w2v['x1'], w2v['x2']):\n",
        "    ax.annotate(word, (x1, x2))\n",
        "\n",
        "PADDING = 1.0\n",
        "x_axis_min = np.min(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.min(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.max(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.max(vectors, axis=0)[1] + PADDING\n",
        "\n",
        "plt.xlim(x_axis_min, x_axis_max)\n",
        "plt.ylim(y_axis_min, y_axis_max)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FqRD2yrfNdJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}