{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTS-RX0XNdJF"
      },
      "source": [
        "# 한국어 word2vec 작성\n",
        "\n",
        "- skipgram, window size 2 의 simplified word2vec model 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3XXscvEafNs"
      },
      "outputs": [],
      "source": [
        "# Install konlpy\n",
        "!curl -s https://raw.githubusercontent.com/teddylee777/machine-learning/master/99-Misc/01-Colab/mecab-colab.sh | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wC6_rxXQXWq"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "세션 재시작하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IdNzusOZNdJH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAyFLxJyNdJI"
      },
      "source": [
        "### Toy 말뭉치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ROpJ63O9NdJI"
      },
      "outputs": [],
      "source": [
        "corpus = ['왕은 매우 강한 남자이다',\n",
        "          '여왕은 현명한 예쁜 여자이다',\n",
        "          '소년은 젊은 남자이다',\n",
        "          '소녀는 젊은 예쁜 여자이다',\n",
        "          '왕자는 젊고 현명한 왕이 될 것이다',\n",
        "          '공주는 젊고 예쁜 현명한 여왕이 될 것이다',\n",
        "          '남자는 강하다',\n",
        "          '여자는 예쁘다',\n",
        "          '왕자는 왕이 될 소년이다',\n",
        "          '공주는 왕비가 될 소녀이다']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l-9me-_NdJJ",
        "outputId": "c2717030-1337-42c6-d58e-028ad520d6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "왕은 매우 강한 남자이다\n",
            "여왕은 현명한 예쁜 여자이다\n",
            "소년은 젊은 남자이다\n",
            "소녀는 젊은 예쁜 여자이다\n",
            "왕자는 젊고 현명한 왕이 될 것이다\n",
            "공주는 젊고 예쁜 현명한 여왕이 될 것이다\n",
            "남자는 강하다\n",
            "여자는 예쁘다\n",
            "왕자는 왕이 될 소년이다\n",
            "공주는 왕비가 될 소녀이다\n"
          ]
        }
      ],
      "source": [
        "cleaned_corpus = []\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "    text = re.sub(r'[^a가-힣]', '', text)  #한글\n",
        "    cleaned_corpus.append(text.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ID2G0kNdJJ"
      },
      "source": [
        "### stopword 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EPlKopmNdJK",
        "outputId": "90ee5676-e245-44d3-d953-38451bfc8289"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method Okt.morphs of <konlpy.tag._okt.Okt object at 0x7de13c11fcd0>>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "okt.morphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ijg4GRBTNdJK"
      },
      "outputs": [],
      "source": [
        "stop_words = ['은', '가', '이다', '는', '이', '될']\n",
        "\n",
        "results = []\n",
        "\n",
        "for text in corpus:\n",
        "    tmp = []\n",
        "    for word in okt.morphs(text):\n",
        "        if word not in stop_words:\n",
        "            tmp.append(word)\n",
        "    results.append(' '.join(tmp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9nXQuw2NdJK",
        "outputId": "de52ad0b-3837-4b3d-a816-357502c463ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['왕 매우 강한 남자',\n",
              " '여왕 현명한 예쁜 여자',\n",
              " '소년 젊은 남자',\n",
              " '소녀 젊은 예쁜 여자',\n",
              " '왕자 젊고 현명한 왕 것',\n",
              " '공주 젊고 예쁜 현명한 여왕 것',\n",
              " '남자 강하다',\n",
              " '여자 예쁘다',\n",
              " '왕자 왕 소년',\n",
              " '공주 왕비 소녀']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_corpus = results\n",
        "cleaned_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Iko9aUJNdJL"
      },
      "source": [
        "### vocaburary 모음 작성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erhHSb16NdJL",
        "outputId": "c8689f1f-9c4b-4003-8aaa-9bdb3c6d7ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['젊고',\n",
              " '소년',\n",
              " '소녀',\n",
              " '예쁘다',\n",
              " '남자',\n",
              " '현명한',\n",
              " '젊은',\n",
              " '여자',\n",
              " '매우',\n",
              " '왕',\n",
              " '예쁜',\n",
              " '것',\n",
              " '공주',\n",
              " '강하다',\n",
              " '여왕',\n",
              " '왕자',\n",
              " '왕비',\n",
              " '강한']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = []\n",
        "\n",
        "for sentence in cleaned_corpus:\n",
        "    for word in sentence.split(' '):\n",
        "        words.append(word)\n",
        "\n",
        "words = list(set(words))\n",
        "words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpPni9I3NdJL"
      },
      "source": [
        "### word-to-index, index-to-word 작성\n",
        "\n",
        "- word 를 index 로 변환  \n",
        "\n",
        "- sentence 를 word index 로 변환  \n",
        "\n",
        "- window size 에 따라 train data 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "enx1Sy5gNdJL"
      },
      "outputs": [],
      "source": [
        "word2index = dict((w, i) for i, w in enumerate(words))\n",
        "index2word = dict((i, w) for i, w in enumerate(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57n1x1qcNdJM",
        "outputId": "390e8f21-9010-47c1-abfc-80ac0f705c9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'젊고': 0,\n",
              " '소년': 1,\n",
              " '소녀': 2,\n",
              " '예쁘다': 3,\n",
              " '남자': 4,\n",
              " '현명한': 5,\n",
              " '젊은': 6,\n",
              " '여자': 7,\n",
              " '매우': 8,\n",
              " '왕': 9,\n",
              " '예쁜': 10,\n",
              " '것': 11,\n",
              " '공주': 12,\n",
              " '강하다': 13,\n",
              " '여왕': 14,\n",
              " '왕자': 15,\n",
              " '왕비': 16,\n",
              " '강한': 17}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QSsOL1dNdJM"
      },
      "source": [
        "### skip-gram 으로 training data 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ3t2gBLNdJM",
        "outputId": "47411c46-cfbc-4284-cceb-161db57df84f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['왕', '매우', '강한', '남자'],\n",
              " ['여왕', '현명한', '예쁜', '여자'],\n",
              " ['소년', '젊은', '남자'],\n",
              " ['소녀', '젊은', '예쁜', '여자'],\n",
              " ['왕자', '젊고', '현명한', '왕', '것'],\n",
              " ['공주', '젊고', '예쁜', '현명한', '여왕', '것'],\n",
              " ['남자', '강하다'],\n",
              " ['여자', '예쁘다'],\n",
              " ['왕자', '왕', '소년'],\n",
              " ['공주', '왕비', '소녀']]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences = []\n",
        "for sentence in cleaned_corpus:\n",
        "    sentences.append(sentence.split())\n",
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IRPTmtxGNdJM"
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] :\n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZQ3L69NdJM",
        "outputId": "7c6bded9-ba89-4c45-dccd-34a0e5dce317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['왕', '매우'],\n",
              " ['왕', '강한'],\n",
              " ['매우', '왕'],\n",
              " ['매우', '강한'],\n",
              " ['매우', '남자'],\n",
              " ['강한', '왕'],\n",
              " ['강한', '매우'],\n",
              " ['강한', '남자'],\n",
              " ['남자', '매우'],\n",
              " ['남자', '강한']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5-ZnifbvNdJM",
        "outputId": "0062bb4e-f05b-4ee4-cd24-538523322c89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4e22fe76-0bb7-49b5-9004-b5fd1aebc910\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>왕</td>\n",
              "      <td>매우</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>왕</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>매우</td>\n",
              "      <td>왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>매우</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>매우</td>\n",
              "      <td>남자</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e22fe76-0bb7-49b5-9004-b5fd1aebc910')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e22fe76-0bb7-49b5-9004-b5fd1aebc910 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e22fe76-0bb7-49b5-9004-b5fd1aebc910');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e43aa026-ae43-4275-9549-f96959fcd9ca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e43aa026-ae43-4275-9549-f96959fcd9ca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e43aa026-ae43-4275-9549-f96959fcd9ca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  input label\n",
              "0     왕    매우\n",
              "1     왕    강한\n",
              "2    매우     왕\n",
              "3    매우    강한\n",
              "4    매우    남자"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lom09YKYNdJN"
      },
      "source": [
        "### One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMftiqg0NdJN",
        "outputId": "96e3fab8-af2b-43a4-8bdd-0c44820a345a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "len(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg4aGj-0NdJN"
      },
      "source": [
        "### One hot encoding 된 train, label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "it0xjkFmNdJN"
      },
      "outputs": [],
      "source": [
        "X = [] # input word\n",
        "Y = [] # target word\n",
        "\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    X.append(to_categorical(word2index[x], len(words)))\n",
        "    Y.append(to_categorical(word2index[x], len(words)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsIERp49NdJN",
        "outputId": "c7b9e540-e30e-48e0-e18d-beba8c495e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32)]\n",
            "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32)]\n"
          ]
        }
      ],
      "source": [
        "print(X[:3])\n",
        "print(Y[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P2Obs9yFNdJN"
      },
      "outputs": [],
      "source": [
        "# convert them to numpy arrays\n",
        "X_train = np.array(X)\n",
        "Y_train = np.array(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ab9QTmDNdJN"
      },
      "source": [
        "**시각화를 위해 hidden layer 의 unit 을 2 로 제한**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PAtqd6iaNdJN"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(2, input_dim=len(words)))\n",
        "model.add(Dense(len(words)))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfFvzj9tNdJN",
        "outputId": "2c03ecc8-9666-4149-c365-61217728bc0b",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 8.6043 - accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.3038 - accuracy: 0.0357\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 9.4027 - accuracy: 0.0595\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 8ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595 \n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595    \n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 8.8266 - accuracy: 0.0595\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7de09c2a9810>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs=500, batch_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBm9JWQyNdJN"
      },
      "source": [
        "### 첫번째 Hidden Layer 추출 및 weight + bias 를 vector 로 합산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaLL_1xHNdJN",
        "outputId": "0724f3ff-4dd6-4416-e26a-d33e5c9f529b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2)                 38        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                54        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92 (368.00 Byte)\n",
            "Trainable params: 92 (368.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YVVWbleNdJO",
        "outputId": "a5ecea09-922d-4376-85f5-254b45687bae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.41871086, -0.543144  ],\n",
              "        [ 0.00138753, -0.46068326],\n",
              "        [ 0.27011922, -0.26410815],\n",
              "        [ 0.4465863 ,  0.2264269 ],\n",
              "        [-0.29233298, -0.06572312],\n",
              "        [-0.04172575, -0.27380866],\n",
              "        [-0.17269161, -0.18121499],\n",
              "        [ 0.21609235,  0.2727946 ],\n",
              "        [-0.43461627, -0.02151918],\n",
              "        [-0.29345304,  0.17721629],\n",
              "        [-0.49799988, -0.551796  ],\n",
              "        [-0.05005118,  0.07679216],\n",
              "        [-0.148121  , -0.53803307],\n",
              "        [ 0.06383353, -0.5107018 ],\n",
              "        [ 0.49617374, -0.00795734],\n",
              "        [-0.47770536,  0.00904149],\n",
              "        [ 0.2027029 ,  0.4078645 ],\n",
              "        [ 0.29777387, -0.1658304 ]], dtype=float32),\n",
              " array([-0.0121728 , -0.02490589], dtype=float32)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.layers[0].get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5qIPzp6NdJO",
        "outputId": "b18da149-f1dd-4db5-ccd6-094d99002986"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.43088365, -0.5680499 ],\n",
              "       [-0.01078528, -0.48558915],\n",
              "       [ 0.25794643, -0.28901404],\n",
              "       [ 0.43441352,  0.20152101],\n",
              "       [-0.30450577, -0.09062901]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectors= model.layers[0].get_weights()[0] + model.layers[0].get_weights()[1]\n",
        "vectors[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8AbOvoHNdJO",
        "outputId": "fe262abc-5d29-44fa-c608-31ebdc570ad4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['젊고',\n",
              " '소년',\n",
              " '소녀',\n",
              " '예쁘다',\n",
              " '남자',\n",
              " '현명한',\n",
              " '젊은',\n",
              " '여자',\n",
              " '매우',\n",
              " '왕',\n",
              " '예쁜',\n",
              " '것',\n",
              " '공주',\n",
              " '강하다',\n",
              " '여왕',\n",
              " '왕자',\n",
              " '왕비',\n",
              " '강한']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "OBgTTD04NdJO",
        "outputId": "564c3f7f-020f-4926-ebfb-a6d91d629c63"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ef98211a-158f-43a1-b767-419de3ca405d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.430884</td>\n",
              "      <td>-0.568050</td>\n",
              "      <td>젊고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.010785</td>\n",
              "      <td>-0.485589</td>\n",
              "      <td>소년</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.257946</td>\n",
              "      <td>-0.289014</td>\n",
              "      <td>소녀</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.434414</td>\n",
              "      <td>0.201521</td>\n",
              "      <td>예쁘다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.304506</td>\n",
              "      <td>-0.090629</td>\n",
              "      <td>남자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.053899</td>\n",
              "      <td>-0.298715</td>\n",
              "      <td>현명한</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.184864</td>\n",
              "      <td>-0.206121</td>\n",
              "      <td>젊은</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.203920</td>\n",
              "      <td>0.247889</td>\n",
              "      <td>여자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.446789</td>\n",
              "      <td>-0.046425</td>\n",
              "      <td>매우</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.305626</td>\n",
              "      <td>0.152310</td>\n",
              "      <td>왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.510173</td>\n",
              "      <td>-0.576702</td>\n",
              "      <td>예쁜</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.062224</td>\n",
              "      <td>0.051886</td>\n",
              "      <td>것</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.160294</td>\n",
              "      <td>-0.562939</td>\n",
              "      <td>공주</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.051661</td>\n",
              "      <td>-0.535608</td>\n",
              "      <td>강하다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.484001</td>\n",
              "      <td>-0.032863</td>\n",
              "      <td>여왕</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.489878</td>\n",
              "      <td>-0.015864</td>\n",
              "      <td>왕자</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.190530</td>\n",
              "      <td>0.382959</td>\n",
              "      <td>왕비</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.285601</td>\n",
              "      <td>-0.190736</td>\n",
              "      <td>강한</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef98211a-158f-43a1-b767-419de3ca405d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef98211a-158f-43a1-b767-419de3ca405d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef98211a-158f-43a1-b767-419de3ca405d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecd955e3-e070-41a3-9d65-91a379d8b511\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecd955e3-e070-41a3-9d65-91a379d8b511')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecd955e3-e070-41a3-9d65-91a379d8b511 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_44f49a3d-9ffa-47a3-985b-5bf2b111bd59\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('w2v')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_44f49a3d-9ffa-47a3-985b-5bf2b111bd59 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('w2v');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          x1        x2 word\n",
              "0  -0.430884 -0.568050   젊고\n",
              "1  -0.010785 -0.485589   소년\n",
              "2   0.257946 -0.289014   소녀\n",
              "3   0.434414  0.201521  예쁘다\n",
              "4  -0.304506 -0.090629   남자\n",
              "5  -0.053899 -0.298715  현명한\n",
              "6  -0.184864 -0.206121   젊은\n",
              "7   0.203920  0.247889   여자\n",
              "8  -0.446789 -0.046425   매우\n",
              "9  -0.305626  0.152310    왕\n",
              "10 -0.510173 -0.576702   예쁜\n",
              "11 -0.062224  0.051886    것\n",
              "12 -0.160294 -0.562939   공주\n",
              "13  0.051661 -0.535608  강하다\n",
              "14  0.484001 -0.032863   여왕\n",
              "15 -0.489878 -0.015864   왕자\n",
              "16  0.190530  0.382959   왕비\n",
              "17  0.285601 -0.190736   강한"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v['word'] = words\n",
        "w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "MdFfXRIZNdJO",
        "outputId": "ecebe1f8-de3d-42c5-afeb-b5ed0747ef8c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False               #한글사용시 마이너스 사인 깨짐 방지\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "for word, x1, x2 in zip(w2v['word'], w2v['x1'], w2v['x2']):\n",
        "    ax.annotate(word, (x1, x2))\n",
        "\n",
        "PADDING = 1.0\n",
        "x_axis_min = np.min(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.min(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.max(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.max(vectors, axis=0)[1] + PADDING\n",
        "\n",
        "plt.xlim(x_axis_min, x_axis_max)\n",
        "plt.ylim(y_axis_min, y_axis_max)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqRD2yrfNdJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
